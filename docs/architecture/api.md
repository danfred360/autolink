# API

Framework: We implement the backend as a RESTful API using Node.js and Express.js. Express is a lightweight, unopinionated framework that allows us to define our routes and middleware flexibly, which suits our needs for a custom API. The API is organized into modular route handlers by resource (cars, maintenance, fuel-ups, parts), making it easy to maintain and extend. We chose REST for its simplicity and broad support – the mobile app can communicate with JSON over HTTPS, and the endpoints follow intuitive resource-based URLs.

Endpoints Design: The API exposes endpoints to manage cars and their related data (maintenance records, fuel-ups, parts). Endpoints are organized by resource, with hierarchical routes where appropriate, and use standard HTTP methods (GET, POST, PUT, DELETE) for CRUD operations. For example:
	•	Cars: GET /api/cars retrieves the authenticated user’s car list (and possibly an admin could get all cars), POST /api/cars adds a new car, GET /api/cars/{id} fetches details of a specific car, PUT /api/cars/{id} updates it, and DELETE /api/cars/{id} removes it (if allowed).
	•	Maintenance: GET /api/cars/{id}/maintenance lists all maintenance records for a given car, POST /api/cars/{id}/maintenance creates a new maintenance entry for that car, GET /api/maintenance/{recordId} retrieves a specific maintenance record (this could alternatively be nested under car), and corresponding PUT/DELETE for updates or deletion of a record.
	•	Fuel-ups: Similarly, GET /api/cars/{id}/fuel-ups lists fuel logs for a car, POST /api/cars/{id}/fuel-ups adds a new fuel-up entry, etc. We might also have summary routes (e.g., GET /api/cars/{id}/fuel-ups/stats for average mileage calculations) in the future.
	•	Parts: If we maintain a parts catalog or need to fetch parts details, endpoints like GET /api/parts (or perhaps integrated with maintenance, e.g., GET /api/maintenance/{id}/parts to list parts used in a maintenance record) will be provided. Parts might primarily be manipulated through maintenance records (for adding parts to a record) rather than standalone, but we have flexibility to adjust this as needed.

All endpoints enforce proper request validation – the API will validate request bodies and parameters (for example, ensuring required fields like car make/model are present on creation, numeric fields like odometer are positive, etc.) to maintain data integrity. Where possible, we use semantic HTTP response codes (200 OK, 201 Created, 400 Bad Request for validation errors, 401 Unauthorized or 403 Forbidden for auth issues, 500 for unexpected errors, etc.). The API also returns useful error messages in JSON so the app can display feedback to the user.

We document the API (e.g., using OpenAPI/Swagger) for clarity and to ease future integration. This documentation covers each route, allowed methods, required fields, and example responses, reducing the chance of misuse and aiding future developers or third-party integrators.

Security Measures: Security is a top priority in the API design. All endpoints (except maybe public health checks or an authentication route) require proper authentication and authorization. We implement OAuth 2.0 bearer token authentication for API requests – initially via our own JWT tokens (issued at login), and potentially integrating a full OAuth2 provider in the future (see Auth section). Every request must include a valid token; the Express middleware will verify the JWT signature and check token expiry and scopes/roles before allowing access ￼. This ensures that only authenticated users can hit protected endpoints, and it prevents anonymous abuse of the API.

We also enforce role-based access control (RBAC) on the backend. Each user has roles (e.g., “user” or “admin”) which are embedded in their token or looked up in the database. Handlers will verify that the user has permission to perform the action. For example, a regular user can only access their own car and record data (the API will check that the {id} in the route belongs to the authenticated user’s account), while an admin role might be allowed to access or manage all users’ data for administrative purposes. We follow the principle of least privilege – each API endpoint grants the minimum level of access needed ￼. This prevents users from accessing or modifying data that isn’t theirs.

To further secure the API, we implement rate limiting to thwart abuse and DDoS attacks. Using a middleware (like express-rate-limit), we limit clients to a reasonable number of requests per minute ￼ ￼. This prevents any single IP or user from overwhelming the server with too many requests in a short time. If the limit is exceeded, the API responds with HTTP 429 (Too Many Requests) and a friendly error message. The limits are configured with typical values (e.g., 100 requests per 15 minutes by default) and can be adjusted as needed ￼. For flexibility, we can apply stricter rate limits to sensitive endpoints (like auth or heavy report generation) and higher limits to lightweight endpoints. Rate limiting, combined with potential future use of an API gateway, forms a defense against brute force or DDoS attempts ￼.

We also consider deploying an API Gateway in front of the Express service in the future (especially when moving to Kubernetes). An API Gateway (like Kong, Traefik, or cloud-managed gateways) can handle cross-cutting concerns such as authentication, SSL termination, and additional throttling or IP filtering at the edge. For now, with a single service, it’s not strictly necessary, but our design is compatible with using a gateway when scaling up (for example, routing /api traffic through a gateway that then forwards to the Express container).

Other security best practices implemented include using Helmet middleware to set secure HTTP headers (to mitigate XSS and clickjacking), input validation on all endpoints (to prevent injection attacks by sanitizing and validating data ￼), and logging all requests for auditing. All communication to the API will be done over HTTPS to encrypt data in transit. In development, we use HTTP (for simplicity), but in production an TLS termination (load balancer or proxy) will ensure encryption.

Scalability: The API backend is designed to be stateless and easily scalable. We containerize the Express application (e.g., with a Docker image) so that it can be replicated across multiple instances. Because the app does not store session state in memory (we use tokens for auth, which are stateless, and any session data can be stored in the database or a cache), we can run multiple containers behind a load balancer to handle increased load. This horizontal scaling strategy will allow Autolink to serve many concurrent users as the user base grows. The stateless, containerized design also makes it ready for orchestration on Kubernetes in the future – we plan to deploy it on a K8s cluster where we can leverage features like auto-scaling, self-healing, and easy rollouts. Each service (API, database, etc.) will be a separate container, aligning with microservices principles. The API container can be configured with resource limits and can be scaled independently of other components.

In preparation for Kubernetes, we have structured configuration via environment variables (for database URLs, secrets, etc.), which is compatible with ConfigMaps/Secrets on K8s and keeps the container portable. We also include health check endpoints that Kubernetes can use for liveness/readiness probes to manage rolling updates with zero downtime.

Down the line, if one part of the system becomes a bottleneck, the microservice-oriented approach lets us spin it off. For example, if maintenance data processing becomes intensive, we could create a separate service just for that. The REST API layer could evolve or be complemented by GraphQL if more flexible querying is needed (not in scope initially, but possible in the future without breaking the mobile app, by versioning the API).

In summary, the Express API is built to be secure, stateless, and scalable. Containerization and adherence to the 12-factor app principles ensure we can smoothly transition from a single-node setup to a distributed cloud deployment as needed.